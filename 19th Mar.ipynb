{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.**\n",
    "\n",
    "Min-Max scaling is a data preprocessing technique used to transform the features of a dataset to a specific range, usually between 0 and 1. This is achieved by subtracting the minimum value of the feature from each data point and then dividing by the range (difference between maximum and minimum values). Min-Max scaling is particularly useful when features have different scales and ranges, and you want to normalize them to ensure that they have a similar impact on the model.\n",
    "\n",
    "Example:\n",
    "Suppose you have a dataset of house prices with a feature \"square footage\" that ranges from 800 to 2500 square feet. Applying Min-Max scaling would transform these values into a new range of 0 to 1, making it easier for machine learning algorithms to work with them. If a house has a square footage of 1200, after Min-Max scaling, it would be transformed to (1200 - 800) / (2500 - 800) = 0.25.\n",
    "\n",
    "**Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.**\n",
    "\n",
    "The Unit Vector technique, also known as normalization or L2 normalization, scales the feature vectors so that they have a Euclidean norm (magnitude) of 1. It involves dividing each data point by the Euclidean norm of the entire feature vector. Unlike Min-Max scaling, which focuses on bringing the features within a specific range, Unit Vector scaling focuses on direction preservation.\n",
    "\n",
    "Example:\n",
    "Consider a dataset with two features: \"income\" and \"age.\" After performing Unit Vector scaling, each data point's feature vector will be divided by its Euclidean norm, ensuring that the vector's magnitude becomes 1 while preserving the direction of the data in the feature space.\n",
    "\n",
    "**Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.**\n",
    "\n",
    "PCA is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional one while preserving as much of the original data's variability as possible. It achieves this by identifying the principal components, which are linear combinations of the original features that capture the maximum variance in the data.\n",
    "\n",
    "Example:\n",
    "Imagine you have a dataset of customer purchase histories with various features such as \"amount spent on clothing,\" \"amount spent on electronics,\" and so on. By applying PCA, you can find the principal components that explain the most significant variance in the purchase patterns. You might discover that the first principal component emphasizes a general spending trend across all categories, while the second principal component captures the difference between clothing and electronics spending.\n",
    "\n",
    "**Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.**\n",
    "\n",
    "PCA is a form of feature extraction, which involves transforming the original features into a new set of features that represent the data in a more compact and meaningful way. In the context of PCA, these new features are the principal components that are linear combinations of the original features. Each principal component is a new feature that captures a specific direction of maximum variance in the data.\n",
    "\n",
    "Example:\n",
    "Consider a dataset of medical measurements including blood pressure, heart rate, cholesterol levels, and more. Instead of using all these measurements as individual features, you can apply PCA to extract the most significant components. These components might represent underlying health factors, like \"cardiovascular health\" or \"metabolic health,\" that are inferred from the original measurements.\n",
    "\n",
    "**Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.**\n",
    "\n",
    "In this case, you would apply Min-Max scaling to ensure that the features \"price,\" \"rating,\" and \"delivery time\" are normalized and have a similar impact on the recommendation system. The steps would be as follows:\n",
    "\n",
    "1. Calculate the minimum and maximum values for each feature in the dataset (price, rating, delivery time).\n",
    "2. For each data point, subtract the minimum value of the respective feature and then divide by the range (maximum - minimum) for that feature.\n",
    "\n",
    "This process would transform the features into a common range of values between 0 and 1, making them compatible for the recommendation system and preventing any feature from dominating the others due to different scales.\n",
    "\n",
    "**Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.**\n",
    "\n",
    "In the context of predicting stock prices, you might have a dataset with numerous features related to various financial metrics and market indicators. However, too many features can lead to overfitting and increased computational complexity. Here's how you could use PCA to reduce dimensionality:\n",
    "\n",
    "1. Standardize the dataset: Normalize each feature so that they all have mean zero and unit variance. This step ensures that features with larger scales don't dominate the PCA.\n",
    "\n",
    "2. Calculate the covariance matrix: Compute the covariance matrix of the standardized dataset. This matrix contains information about the relationships between the features.\n",
    "\n",
    "3. Compute eigenvectors and eigenvalues: Perform eigendecomposition on the covariance matrix to obtain the eigenvectors and corresponding eigenvalues. Eigenvectors represent the directions of maximum variance, and eigenvalues indicate the magnitude of variance along those directions.\n",
    "\n",
    "4. Select principal components: Sort the eigenvectors by their corresponding eigenvalues in decreasing order. Choose the top k eigenvectors to retain, where k is the desired reduced dimensionality.\n",
    "\n",
    "5. Project data onto the new feature space: Multiply the original standardized data by the selected eigenvectors to obtain the reduced-dimensional feature representation.\n",
    "\n",
    "By retaining a smaller number of principal components, you capture the most significant variability in the data while reducing its dimensionality. These principal components can then be used as features for training your stock price prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([1, 5, 10, 15, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   1\n",
       "1   5\n",
       "2  10\n",
       "3  15\n",
       "4  20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(scaler.fit_transform(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.000000\n",
       "1  0.210526\n",
       "2  0.473684\n",
       "3  0.736842\n",
       "4  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "Choose the Number of Principal Components: Decide on a threshold for the amount of variance you want to retain. A common approach is to choose a threshold like 95% or 99% of the total variance. You can determine how many principal components are needed to reach this threshold.\n",
    "\n",
    "Dimensionality Reduction: Retain the chosen number of principal components and project your data onto the new reduced-dimensional feature space.\n",
    "\n",
    "The number of principal components to retain is a balance between maintaining meaningful information and reducing dimensionality. If you choose to retain too few principal components, you might lose important information and result in a model that performs poorly. If you retain too many principal components, you might not achieve significant dimensionality reduction.\n",
    "\n",
    "In a healthcare-related dataset like the one you provided ([height, weight, age, gender, blood pressure]), a common starting point might be to aim for a cumulative explained variance of around 95%. You can calculate the cumulative explained variance and see how many principal components are needed to achieve this level. If, for example, you find that the first 3 or 4 principal components capture around 95% of the variance, you might choose to retain those components.\n",
    "\n",
    "Ultimately, the choice of the number of principal components depends on the specific characteristics of your data and the goals of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:\\\\Programming\\\\coding\\\\Pwskills\\\\Excel files\\\\Book1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Systolic BP</th>\n",
       "      <th>Diastolic BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>125</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Height (cm)    Weight (kg)    Age    Gender    Systolic BP   \\\n",
       "0            165             68     30   Female             120   \n",
       "1            178             80     45   Male               130   \n",
       "2            155             52     28   Female             110   \n",
       "3            182             95     60   Male               140   \n",
       "4            170             75     35   Male               125   \n",
       "\n",
       "    Diastolic BP   \n",
       "0              80  \n",
       "1              85  \n",
       "2              70  \n",
       "3              90  \n",
       "4              82  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Height (cm) ', ' Weight (kg) ', ' Age ', ' Gender ', ' Systolic BP ',\n",
       "       ' Diastolic BP '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(scaler.fit_transform(df1[[' Height (cm) ', ' Weight (kg) ', ' Age ',' Systolic BP ',' Diastolic BP ']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96112283])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = np.argmax(explained_variance >= 0.95) +1\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduce = pd.DataFrame(pca.fit_transform(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.389489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.114709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.120205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.043615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0 -0.389489\n",
       "1  0.427608\n",
       "2 -1.114709\n",
       "3  1.120205\n",
       "4 -0.043615"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
