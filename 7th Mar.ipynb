{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. What are the three measures of central tendency?\n",
    "\n",
    "The three measures of central tendency are:\n",
    "\n",
    "1. Mean: The mean is the average of a set of values. It is calculated by summing up all the values in the dataset and then dividing by the total number of values. The mean is sensitive to extreme values, as it takes into account the magnitude of each value.\n",
    "\n",
    "2. Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. If there is an odd number of values, the median is the middle value. If there is an even number of values, the median is the average of the two middle values. The median is less affected by extreme values and is a good measure of central tendency for skewed distributions.\n",
    "\n",
    "3. Mode: The mode is the most frequently occurring value in a dataset. It represents the value that appears with the highest frequency. In some cases, a dataset may have multiple modes (multimodal) or no mode if all the values are unique. The mode is useful for categorical or discrete data, but it can also be used for continuous data by grouping values into intervals or bins.\n",
    "\n",
    "These measures provide different perspectives on the central tendency of a dataset and can be used to understand the typical or representative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between the mean, median, and mode? How are they used to measure the\n",
    "# central tendency of a dataset?\n",
    "\n",
    "The mean, median, and mode are different measures of central tendency that provide insights into the typical or representative value of a dataset. Here are their differences and how they are used:\n",
    "\n",
    "1. Mean: The mean is calculated by summing up all the values in a dataset and then dividing by the total number of values. It takes into account the magnitude of each value. The mean is sensitive to extreme values, as it incorporates all values in the calculation. It is commonly used in situations where the dataset follows a roughly symmetric distribution and is not heavily influenced by outliers. For example, it is used to calculate the average score of students in a class.\n",
    "\n",
    "2. Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. If there is an odd number of values, the median is the middle value. If there is an even number of values, the median is the average of the two middle values. The median is less affected by extreme values and is a robust measure of central tendency for skewed distributions or datasets with outliers. It is commonly used when the dataset is not symmetrically distributed or when extreme values may distort the mean. For example, it is used to determine the middle salary in a company.\n",
    "\n",
    "3. Mode: The mode is the most frequently occurring value in a dataset. It represents the value that appears with the highest frequency. In some cases, a dataset may have multiple modes (multimodal) or no mode if all the values are unique. The mode is useful for categorical or discrete data, but it can also be used for continuous data by grouping values into intervals or bins. The mode is commonly used to identify the most common category or value in a dataset. For example, it is used to determine the most popular color in a survey.\n",
    "\n",
    "By using these measures of central tendency, analysts can gain a better understanding of the distribution and characteristics of the dataset. The choice of which measure to use depends on the nature of the data and the purpose of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Measure the three measures of central tendency for the given height data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats \n",
    "arr=np.array([178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.01875\n",
      "177.0\n",
      "ModeResult(mode=array([177.]), count=array([3]))\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(arr))\n",
    "print(np.median(arr))\n",
    "print(stats.mode(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Find the standard deviation for the given data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7885814036548633"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. How are measures of dispersion such as range, variance, and standard deviation used to describe\n",
    "# the spread of a dataset? Provide an example.\n",
    "\n",
    "Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide information about how the values in a dataset are spread out or clustered around the central tendency measures.\n",
    "\n",
    "1. Range: The range is the simplest measure of dispersion and represents the difference between the maximum and minimum values in a dataset. It gives an idea of the total spread of the data but does not take into account the distribution of values within that range. For example, if you have a dataset of exam scores ranging from 60 to 95, the range would be 35.\n",
    "\n",
    "2. Variance: Variance measures the average squared deviation of each data point from the mean of the dataset. It quantifies the spread by calculating how much the values deviate from the mean. A higher variance indicates greater dispersion, while a lower variance indicates less dispersion. However, the variance is measured in squared units, which may not be easily interpretable. For example, in a dataset of exam scores, a variance of 100 indicates more spread than a variance of 25.\n",
    "\n",
    "3. Standard Deviation: The standard deviation is the square root of the variance. It provides a measure of dispersion in the original units of the dataset and is widely used due to its interpretability. It represents the average distance between each data point and the mean, indicating how tightly or widely the values are clustered around the mean. A higher standard deviation implies a greater spread, while a lower standard deviation indicates less spread. For example, if you have a dataset of exam scores with a standard deviation of 10, it means that, on average, each score deviates from the mean by approximately 10 points.\n",
    "\n",
    "To illustrate, let's consider a dataset of daily temperatures in Celsius for a particular city over a week: [28, 30, 27, 29, 31, 26, 28]. We can calculate the measures of dispersion as follows:\n",
    "\n",
    "Range: The range is the difference between the maximum and minimum values. In this case, the range is 31 - 26 = 5.\n",
    "\n",
    "Variance: First, we calculate the mean temperature: (28 + 30 + 27 + 29 + 31 + 26 + 28) / 7 = 28.14. Then, we compute the squared differences from the mean for each data point: [(28 - 28.14)^2, (30 - 28.14)^2, (27 - 28.14)^2, (29 - 28.14)^2, (31 - 28.14)^2, (26 - 28.14)^2, (28 - 28.14)^2]. Taking the average of these squared differences, we get the variance.\n",
    "\n",
    "Standard Deviation: The standard deviation is the square root of the variance, providing a measure of dispersion in the original units of the dataset.\n",
    "\n",
    "By calculating these measures of dispersion, we can describe the spread or variability of the dataset, helping us understand the degree of variation in the temperatures throughout the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 . What is a Venn diagram?\n",
    "\n",
    "A Venn diagram is a visual representation of the relationships between different sets of objects or elements. It consists of overlapping circles or other closed curves, where each circle represents a set, and the overlapping regions represent the elements that are common to those sets.\n",
    "\n",
    "The primary purpose of a Venn diagram is to show the logical relationships between sets, illustrating the similarities, differences, and intersections between them. The diagram allows you to visualize the extent of overlap or shared elements among different sets and helps in understanding set theory concepts such as union, intersection, and complement.\n",
    "\n",
    "In a Venn diagram, the elements of each set are typically represented as points or symbols within the corresponding circle or curve. The regions where the circles or curves overlap indicate the elements that belong to multiple sets, while the non-overlapping regions represent elements unique to a specific set.\n",
    "\n",
    "Venn diagrams are often used in various fields, including mathematics, statistics, logic, and data analysis, to visually analyze and communicate the relationships between different groups or categories of data. They provide a clear and intuitive way to compare and contrast different sets, aiding in problem-solving, decision-making, and understanding complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. For the two given sets A = (2,3,4,5,6,7) & B = (0,2,6,8,10). Find:\n",
    "(i) A B\n",
    "(ii) A ⋃ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 6}\n",
      "{0, 2, 3, 4, 5, 6, 7, 8, 10}\n"
     ]
    }
   ],
   "source": [
    "A = {2,3,4,5,6,7}\n",
    "B = {0,2,6,8,10}\n",
    "print(set.intersection(A,B))\n",
    "print(set.union(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8. What do you understand about skewness in data?\n",
    "\n",
    "Skewness in data refers to the asymmetry or lack of symmetry in the distribution of values. It measures the extent to which a dataset's distribution deviates from a perfectly symmetrical bell-shaped curve (a normal distribution). Skewness is an important statistical concept that provides insights into the shape and characteristics of a dataset.\n",
    "\n",
    "There are three types of skewness:\n",
    "\n",
    "1. Positive Skewness (Right Skewness): In a positively skewed distribution, the tail of the distribution extends towards the right side, and the majority of the values are concentrated on the left side. This means that the dataset has a longer right tail. The mean value is typically greater than the median value in a positively skewed distribution.\n",
    "\n",
    "2. Negative Skewness (Left Skewness): In a negatively skewed distribution, the tail of the distribution extends towards the left side, and the majority of the values are concentrated on the right side. This means that the dataset has a longer left tail. The mean value is typically less than the median value in a negatively skewed distribution.\n",
    "\n",
    "3. Zero Skewness: A perfectly symmetrical distribution, where the dataset is evenly distributed around the mean, has zero skewness. In this case, the mean and the median are equal.\n",
    "\n",
    "Skewness can be quantified using statistical measures such as the skewness coefficient. The skewness coefficient measures the degree and direction of skewness in the dataset. A positive skewness coefficient indicates positive skewness, a negative skewness coefficient indicates negative skewness, and a skewness coefficient close to zero suggests a symmetrical distribution.\n",
    "\n",
    "Understanding skewness is important in data analysis because it affects the interpretation of statistical measures and the choice of appropriate statistical methods. Skewness provides insights into the presence of outliers, the presence of extreme values, and the appropriateness of certain statistical tests that assume a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. If a data is right skewed then what will be the position of median with respect to mean?\n",
    "\n",
    "If a data set is right skewed, the position of the median with respect to the mean will be to the left of the mean.\n",
    "\n",
    "In a right-skewed distribution, the tail of the distribution extends towards the higher values or the right side. This means that there are some extremely high values that pull the mean in that direction. As a result, the mean is typically higher than the median.\n",
    "\n",
    "The median, on the other hand, is less affected by extreme values or outliers compared to the mean. It represents the middle value when the data set is ordered from least to greatest. In a right-skewed distribution, there are relatively more lower values on the left side of the distribution, and the median is positioned closer to these lower values.\n",
    "\n",
    "Therefore, in a right-skewed distribution, the median will be to the left of the mean. This pattern reflects the tendency for the mean to be pulled towards the tail of the distribution due to the influence of the higher values, while the median remains more representative of the central tendency in terms of the position of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10. Explain the difference between covariance and correlation. How are these measures used in\n",
    "# statistical analysis?\n",
    "\n",
    "Covariance and correlation are both measures used to quantify the relationship between two variables in statistical analysis. While they are related, there are some key differences between the two:\n",
    "\n",
    "1. Covariance: Covariance measures the direction and strength of the linear relationship between two variables. It indicates how changes in one variable correspond to changes in the other variable. Covariance can take positive, negative, or zero values. A positive covariance indicates a positive relationship where both variables tend to increase or decrease together. A negative covariance indicates an inverse relationship where one variable tends to increase while the other decreases. A covariance of zero suggests no linear relationship between the variables.\n",
    "\n",
    "Covariance is calculated using the formula:\n",
    "cov(X, Y) = Σ[(X - μX) * (Y - μY)] / (n - 1)\n",
    "\n",
    "where X and Y are the variables, μX and μY are their respective means, and n is the number of observations.\n",
    "\n",
    "2. Correlation: Correlation is a standardized version of covariance that provides a more interpretable measure of the relationship between two variables. It measures both the direction and strength of the linear relationship between variables, but it is scaled to always fall between -1 and 1. A correlation coefficient of 1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.\n",
    "\n",
    "Correlation is calculated using the formula:\n",
    "correlation(X, Y) = cov(X, Y) / (σX * σY)\n",
    "\n",
    "where cov(X, Y) is the covariance between X and Y, σX is the standard deviation of X, and σY is the standard deviation of Y.\n",
    "\n",
    "In statistical analysis, both covariance and correlation are used to understand the relationship between variables:\n",
    "\n",
    "- Covariance is used to measure the strength and direction of the linear relationship between two variables. It is useful for determining whether the variables tend to move together or in opposite directions. However, the value of covariance depends on the scales of the variables, making it difficult to compare across different datasets.\n",
    "\n",
    "- Correlation, on the other hand, standardizes the covariance and provides a measure that is easier to interpret. Correlation coefficients allow for comparison across datasets and indicate the strength and direction of the linear relationship. Correlation is widely used to determine the strength of association between variables, identify trends, and make predictions.\n",
    "\n",
    "Both covariance and correlation are valuable tools in statistical analysis, providing insights into the relationship between variables. They help in understanding patterns, assessing the degree of association, identifying potential dependencies, and selecting appropriate models for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11. What is the formula for calculating the sample mean? Provide an example calculation for a\n",
    "dataset.\n",
    "\n",
    "The formula for calculating the sample mean is:\n",
    "\n",
    "Sample Mean (x̄) = (Sum of all values in the dataset) / (Number of values in the dataset)\n",
    "\n",
    "To calculate the sample mean, you sum up all the values in the dataset and then divide by the total number of values.\n",
    "\n",
    "Let's take an example dataset to calculate the sample mean:\n",
    "\n",
    "Dataset: [10, 12, 15, 14, 13, 11]\n",
    "\n",
    "Step 1: Add up all the values in the dataset: 10 + 12 + 15 + 14 + 13 + 11 = 75\n",
    "\n",
    "Step 2: Count the number of values in the dataset: 6\n",
    "\n",
    "Step 3: Divide the sum of values by the number of values: 75 / 6 = 12.5\n",
    "\n",
    "Therefore, the sample mean of the given dataset is 12.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q12. For a normal distribution data what is the relationship between its measure of central tendency?\n",
    "\n",
    "For a normal distribution, the relationship between the measures of central tendency is as follows:\n",
    "\n",
    "1. Mean: The mean of a normal distribution is located at the center of the distribution. It is also the balancing point of the distribution, where the sum of the deviations of data points from the mean is zero. The mean is equal to the median in a normal distribution.\n",
    "\n",
    "2. Median: The median of a normal distribution is also located at the center of the distribution. It is the value that divides the distribution into two equal halves, with 50% of the data points falling below and 50% falling above the median. The median is equal to the mean in a normal distribution.\n",
    "\n",
    "3. Mode: The mode of a normal distribution is the value or values with the highest frequency or peak in the distribution. In a normal distribution, there is a single mode, and it is equal to the mean and median.\n",
    "\n",
    "In summary, for a normal distribution, the mean, median, and mode are all equal and located at the center of the distribution. This symmetry and equality of the measures of central tendency contribute to the characteristic bell-shaped curve of a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q13. How is covariance different from correlation?\n",
    "\n",
    "Covariance and correlation are both statistical measures that describe the relationship between two variables. While they are related to each other, they have some distinct differences in terms of interpretation and scale.\n",
    "\n",
    "Covariance:\n",
    "Covariance measures the direction and magnitude of the linear relationship between two variables. It quantifies how changes in one variable are associated with changes in the other variable. The formula for covariance between two variables X and Y, based on a set of paired observations, is:\n",
    "\n",
    "Cov(X, Y) = Σ((Xᵢ - X̄)(Yᵢ - Ȳ)) / (N - 1)\n",
    "\n",
    "where:\n",
    "- Σ denotes the summation of the values\n",
    "- Xᵢ and Yᵢ represent individual paired observations\n",
    "- X̄ and Ȳ are the sample means of X and Y, respectively\n",
    "- N is the total number of paired observations\n",
    "\n",
    "Covariance can take any value, positive or negative. A positive covariance indicates a direct or positive relationship between the variables, meaning that when one variable increases, the other tends to increase as well. A negative covariance indicates an inverse or negative relationship, where one variable tends to decrease as the other increases. However, the magnitude of covariance alone does not provide a standardized measure to assess the strength of the relationship.\n",
    "\n",
    "Correlation:\n",
    "Correlation, on the other hand, is a standardized measure of the linear relationship between two variables. It quantifies the strength and direction of the association between variables, irrespective of the scale or units of the variables. The most common correlation coefficient is the Pearson correlation coefficient (r), which ranges from -1 to +1.\n",
    "\n",
    "The formula for the Pearson correlation coefficient between two variables X and Y is:\n",
    "\n",
    "r = Cov(X, Y) / (σₓ * σᵧ)\n",
    "\n",
    "where:\n",
    "- Cov(X, Y) is the covariance between X and Y\n",
    "- σₓ and σᵧ are the standard deviations of X and Y, respectively\n",
    "\n",
    "Correlation coefficient values near +1 indicate a strong positive linear relationship, values near -1 indicate a strong negative linear relationship, and values near 0 indicate a weak or no linear relationship between the variables.\n",
    "\n",
    "In summary, the key differences between covariance and correlation are:\n",
    "- Covariance measures the direction and magnitude of the linear relationship between variables, while correlation measures the strength and direction of the linear relationship.\n",
    "- Covariance is not standardized and depends on the scale of the variables, while correlation is standardized and ranges from -1 to +1.\n",
    "- Correlation provides a more interpretable measure of the relationship, as it is not affected by the scale or units of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q14. How do outliers affect measures of central tendency and dispersion? Provide an example.\n",
    "Outliers can have a significant impact on measures of central tendency and dispersion, potentially distorting the overall understanding of the data. Here's an example to illustrate their effects:\n",
    "\n",
    "Let's consider a dataset representing the incomes of a group of individuals: [10, 15, 20, 25, 30, 35, 40, 1000]. In this dataset, the majority of the incomes are between 10 and 40, but there is one extreme outlier at 1000.\n",
    "\n",
    "Effects on Measures of Central Tendency:\n",
    "1. Mean: The mean is highly affected by outliers since it takes into account all values. In this example, the mean income would be (10+15+20+25+30+35+40+1000)/8 = 153.75. The presence of the outlier significantly inflates the mean income, making it an unreliable representation of the central tendency.\n",
    "\n",
    "2. Median: The median is less affected by outliers since it is simply the middle value when the data is sorted. In this example, the median income would be 27.5, which is a better representation of the central tendency compared to the mean. The median is generally more robust to outliers.\n",
    "\n",
    "Effects on Measures of Dispersion:\n",
    "1. Variance and Standard Deviation: Both variance and standard deviation are influenced by outliers. Since these measures involve squaring the deviations from the mean, outliers with large deviations contribute disproportionately to the calculations. In this example, the presence of the outlier at 1000 would lead to a much higher variance and standard deviation, indicating greater dispersion, even though most of the data points are tightly clustered.\n",
    "\n",
    "2. Interquartile Range (IQR): The IQR is less sensitive to outliers since it focuses on the range between the 25th and 75th percentiles, which are less affected by extreme values. In this example, the IQR would be the difference between the first quartile (15) and the third quartile (35), which is 20. The IQR provides a more robust measure of dispersion compared to the variance and standard deviation.\n",
    "\n",
    "Outliers generally do not have a significant impact on the mode, which is the value or values that appear most frequently in a dataset. The mode represents the peak(s) of the distribution and is determined by the frequencies of the data points rather than their specific values.\n",
    "\n",
    "In summary, outliers can greatly impact measures of central tendency and dispersion. They can skew the mean, while the median is more resistant. Outliers also tend to inflate variance and standard deviation, while the interquartile range is less influenced by extreme values. Therefore, it's important to consider the presence of outliers and evaluate measures of central tendency and dispersion accordingly to avoid misleading interpretations of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
