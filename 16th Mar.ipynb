{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?**\n",
    "\n",
    "- **Overfitting:** Overfitting happens when a model learns the training data too well, including the noise or random fluctuations in the data. This makes the model perform excellently on the training data but poorly on new, unseen data.\n",
    "- **Consequences of Overfitting:** The model won't generalize, leading to poor predictions on real-world data. It memorizes the training data instead of learning patterns.\n",
    "- **Mitigation of Overfitting:** Use simpler models, collect more data, apply regularization techniques, and perform cross-validation to identify overfitting.\n",
    "\n",
    "- **Underfitting:** Underfitting occurs when a model is too simple to capture the underlying patterns in the data. It performs poorly on both training and new data.\n",
    "- **Consequences of Underfitting:** The model misses out on important patterns, leading to inaccurate predictions.\n",
    "- **Mitigation of Underfitting:** Use more complex models, provide more relevant features, and adjust hyperparameters.\n",
    "\n",
    "**Q2: How can we reduce overfitting? Explain in brief.**\n",
    "- Reduce model complexity: Use simpler models that are less likely to memorize noise.\n",
    "- Regularization: Add penalties to the model's loss function for using complex patterns.\n",
    "- Cross-validation: Split data into multiple folds to evaluate model performance and detect overfitting.\n",
    "- Feature selection: Choose only relevant features to avoid overfitting to irrelevant data.\n",
    "\n",
    "**Q3: Explain underfitting. List scenarios where underfitting can occur in ML.**\n",
    "- **Underfitting:** Underfitting happens when a model is too simple to understand the data's patterns.\n",
    "- **Scenarios of Underfitting:** When using a linear model for highly non-linear data, not providing enough relevant features, using too few training iterations for complex models.\n",
    "\n",
    "**Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?**\n",
    "- **Bias-Variance Tradeoff:** It's a balance between the error from biased assumptions and the error from being sensitive to variations in data.\n",
    "- **Bias and Variance Relationship:** High bias tends to lead to underfitting, high variance leads to overfitting.\n",
    "- **Effect on Performance:** A well-balanced model finds the right amount of complexity to minimize both errors on new data.\n",
    "\n",
    "**Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?**\n",
    "- **Detecting Overfitting:**\n",
    "  - High training accuracy but low validation/test accuracy.\n",
    "  - Discrepancy between training and validation performance.\n",
    "  - Learning curves showing increasing validation error with more data.\n",
    "\n",
    "- **Detecting Underfitting:**\n",
    "  - Low training and validation accuracy.\n",
    "  - No significant improvement with additional data.\n",
    "  - Learning curves showing converging low performance.\n",
    "\n",
    "**Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?**\n",
    "- **Bias:** Fixed but incorrect assumptions, leading to systematic errors.\n",
    "  - **High Bias Example:** Linear regression applied to a complex non-linear dataset.\n",
    "  \n",
    "- **Variance:** Sensitivity to small changes, capturing noise in data.\n",
    "  - **High Variance Example:** High-degree polynomial regression on a small dataset.\n",
    "\n",
    "**Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.**\n",
    "- **Regularization:** It's a technique to prevent overfitting by adding penalties to the loss function for complex models.\n",
    "- **Common Techniques:**\n",
    "  - **L1 Regularization (Lasso):** Adds the absolute values of coefficients as penalties, effectively driving some coefficients to zero and thus removing features.\n",
    "  - **L2 Regularization (Ridge):** Adds the squared values of coefficients as penalties, shrinking them towards zero without eliminating any features.\n",
    "  - **Elastic Net:** Combines both L1 and L2 regularization for a balanced approach.\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
